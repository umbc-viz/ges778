---
title: "19. Project 2 troubleshooting"
---

```{r}
#| label: setup
#| message: false
library(dplyr)
library(sf)
library(ggplot2)
library(justviz)
```

## Spatial joins

Here's how you can join sf points with sf polygons in order to find, for example, the number of points in each polygon. This example is brownfields per county. Like with other joins, it matters which is on the left & which is on the right. `sf::st_join` has an argument to change from a left join to an inner join by setting `left = TRUE` (the default) to `left = FALSE`, respectively. The geometry after the join will follow the type of object on the left.

```{r}
counties_sf <- tigris::counties(state = "24", cb = TRUE) |>
  select(county = NAMELSAD)

# need to get into same crs
brownfields_transform <- st_transform(brownfields_sf, st_crs(counties_sf)) |>
  # selecting just a subset of columns to make it easier to see what's going on
  select(site = name, is_archived)

st_join(counties_sf, brownfields_transform) |>
  head() # polygon join point = polygon
st_join(brownfields_transform, counties_sf) |>
  head() # point join polygon = point
```

There are 150 rows in the brownfields data, but the first join, the dataframe with points joined onto polygons, has 153 rows. That's because there are 3 counties with no brownfields. To deal with that, I'll redo the join with `left = FALSE` to make it an inner join, so I don't have any counties without brownfields.

```{r}
sites_per_county <- st_join(counties_sf, brownfields_transform, left = FALSE) |>
  # drop geometry---just want data frame for now
  st_drop_geometry() |>
  group_by(county) |>
  summarise(n_total_sites = n(),
            # throwing in another example aggregation
            n_open_sites = sum(!is_archived))

# join back onto counties shape, so every county has a polygon with a count
# that makes sure we get a true 0 observation for counties without sites
sites_per_county_sf <- counties_sf |>
  left_join(sites_per_county, by = "county") |>
  # fill in 0 for counties with no observations
  mutate(across(n_total_sites:n_open_sites, \(x) tidyr::replace_na(x, 0)))

ggplot(sites_per_county_sf) +
  geom_sf(aes(fill = n_open_sites), color = "black", linewidth = 0.2) +
  scale_fill_distiller(palette = "BuPu", direction = 1) +
  labs(title = "Number of current brownfields by county")
```

Maybe a more meaningful thing to do would be a rate, such as brownfields per 100,000 residents or brownfields per square mile, using data from the ACS dataset.

```{r}
sites_per_county_sf |>
  left_join(acs |> select(name, total_pop, area_sqmi), by = c("county" = "name")) |>
  mutate(open_sites_per_100k = (n_open_sites / total_pop) * 100000) |>
  ggplot() +
    geom_sf(aes(fill = open_sites_per_100k), color = "black", linewidth = 0.2) +
    scale_fill_distiller(palette = "BuPu", direction = 1) +
    labs(title = "Current brownfields per 100k residents by county")
```

If instead we were interested in the points themselves but wanted to know what counties they were each in, a join with brownfields on the left would be helpful. For this example it wouldn't be super useful, but for other project ideas (such as finding points within buffers) it could be.

## Lumping factor levels

If you have a variable with several values you want to collapse into one, the easiest way to do this is to make it a factor if it isn't already, then use one of `forcats`' helper functions.

With a character column, we can use `fct_other` or the various `fct_lump_*` functions to select which levels to keep; everything else gets dumped into the "other" category. The advantage of doing this with factors (as opposed to character vectors) is that factor levels have an order, and these functions will automatically put the "order" level last. Here are a few of those functions:

```{r}
# way more medium values than would be useful
art_types <- art_sf |>
  st_drop_geometry() |>
  filter(!is.na(medium))

art_types |>
  count(medium, sort = TRUE) |>
  mutate(share = n / sum(n))
```

Only keep 3 most common levels:

```{r}
art_types |>
  mutate(medium_grps = forcats::fct_lump_n(medium, 
                                           n = 3, 
                                           other_level = "other types")) |>
  count(medium_grps)
```

Only keep levels with at least 12 observations:

```{r}
art_types |>
  mutate(medium_grps = forcats::fct_lump_min(medium, 
                                           min = 12, 
                                           other_level = "other types")) |>
  count(medium_grps)
```

Only keep levels I've specifically chosen (let's say I'm interested in a few sculpture types):

```{r}
art_types |>
  mutate(medium_grps = forcats::fct_other(medium, 
                                          keep = c("concrete", "marble", "limestone", "granite"),
                                          other_level = "other types")) |>
  count(medium_grps)
# rstudio started warning that you need the drop argument also; that's a lie
```


## Booleans / logical values

Going back over the bit of boolean math we talked about: logical values (true / false) can translate in most (all?) languages to numeric values (1 / 0). That gives you some shortcuts when you need to aggregate data based on logical values.

```{r}
x_logic <- c(TRUE, FALSE, TRUE, TRUE, FALSE)

# count of true values
sum(x_logic)

# count of false values
sum(!x_logic)

# share of values that are true
mean(x_logic)
```

## Encoding data to size

If you map data onto the size of a point, encode that information in the point's *area*, not its *radius*. Perception studies show that area is what we're reading more than radius, and you want your data to have a 1 to 1 relationship with the thing you're encoding to (data-to-ink ratio). The default in ggplot is radius, but you can override that with `scale_size_area`. Normally, size scales (e.g. `scale_size_continuous`) would have an argument `range` for the smallest and largest values to use; for area, you give `max_size` as a single number. If you have a 0 in your data, it will have an area of 0, unlike when using the continuous scale.

```{r}
x_area <- data.frame(location = 1:4, 
                     value = c(1, 0, 2, 5))

# why would a value of 0 have a point?? We wouldn't draw a bar in a bar chart
# for a 0 value
ggplot(x_area, aes(x = location, y = 1, size = value)) +
  geom_point() +
  scale_size_continuous(range = c(1, 10))

# still kinda has a dot for 0 but that might be a graphic device artifact..?
ggplot(x_area, aes(x = location, y = 1, size = value)) +
  geom_point() +
  scale_size_area(max_size = 10)
```

